{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises: Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a function which count number of lines and number of words in a text. \n",
    "All the files are in the data the folder: a) Read obama_speech.txt file and count number of lines and words \n",
    "b) Read michelle_obama_speech.txt file and count number of lines and words \n",
    "c) Read donald_speech.txt file and count number of lines and words \n",
    "d) Read melina_trump_speech.txt file and count number of lines and words'''\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_lines_and_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Counting lines\n",
    "    lines = text.split('\\n')\n",
    "    num_lines = len(lines)\n",
    "\n",
    "    # Counting words\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    speech_name = file_path.split('/')[-1].replace(('.txt'), ' ')\n",
    "\n",
    "    return f'Number of lines and words in {speech_name} are {num_lines} and {num_words}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines and words in obama_speech  are 67 and 2400\n",
      "Number of lines and words in michelle_obama_speech  are 83 and 2204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines and words in donald_speech  are 48 and 1259\n",
      "Number of lines and words in melina_trump_speech   are 33 and 1375\n"
     ]
    }
   ],
   "source": [
    "michelle_obama_speech = './michelle_obama_speech.txt'\n",
    "\n",
    "obama_speech = './obama_speech.txt'\n",
    "\n",
    "donald_speech = 'donald_speech.txt'\n",
    "\n",
    "melina_trump_speech  = 'melina_trump_speech.txt '\n",
    "\n",
    "print(count_lines_and_words(obama_speech))\n",
    "print(count_lines_and_words(michelle_obama_speech ))\n",
    "print(count_lines_and_words(donald_speech))\n",
    "print(count_lines_and_words(melina_trump_speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('English', 91),\n",
       " ('French', 45),\n",
       " ('Arabic', 25),\n",
       " ('Spanish', 24),\n",
       " ('Portuguese', 9),\n",
       " ('Russian', 9),\n",
       " ('Dutch', 8),\n",
       " ('German', 7),\n",
       " ('Chinese', 5),\n",
       " ('Serbian', 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 2\n",
    "''' Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages '''\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def most_spoken_language(filepath, number_languages=10):\n",
    "    with open(filepath, 'r', encoding='utf-8-sig') as file:\n",
    "        countries = json.load(file)\n",
    "\n",
    "    # Extract all languages from the list of countries\n",
    "    all_languages = [language for country in countries for language in country[\"languages\"]]\n",
    "\n",
    "    # Count the occurrences of each language\n",
    "    language_counts = {}\n",
    "    for language in all_languages:\n",
    "        language_counts[language] = language_counts.get(language, 0) + 1\n",
    "\n",
    "    # Sort languages by count in descending order\n",
    "    sorted_languages = sorted(language_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the specified number of most spoken languages\n",
    "    return sorted_languages[:number_languages]\n",
    "\n",
    "countries_data = 'countries_data.json'\n",
    "result = most_spoken_language(countries_data, 10)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'China', 'population': 1377422166},\n",
       " {'country': 'India', 'population': 1295210000},\n",
       " {'country': 'United States of America', 'population': 323947000},\n",
       " {'country': 'Indonesia', 'population': 258705000},\n",
       " {'country': 'Brazil', 'population': 206135893},\n",
       " {'country': 'Pakistan', 'population': 194125062},\n",
       " {'country': 'Nigeria', 'population': 186988000},\n",
       " {'country': 'Bangladesh', 'population': 161006790},\n",
       " {'country': 'Russian Federation', 'population': 146599183},\n",
       " {'country': 'Japan', 'population': 126960000}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def most_populated_countries(filename, top_n=10):\n",
    "    with open(filename, 'r', encoding='utf-8-sig') as file:\n",
    "        countries = json.load(file)\n",
    "\n",
    "    # Extract country names and populations\n",
    "    country_populations = [{'country': country['name'], 'population': country['population']} for country in countries]\n",
    "\n",
    "    # Sort countries by population in descending order\n",
    "    sorted_countries = sorted(country_populations, key=lambda x: x['population'], reverse=True)\n",
    "\n",
    "    # Return the top N countries\n",
    "    return sorted_countries[:top_n]\n",
    "\n",
    "# Example usage\n",
    "filename = './countries_data.json'\n",
    "result = most_populated_countries(filename, 10)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises: Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stephen.marquard@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801051412.m05ECIaH010327@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "stephen.marquard@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "stephen.marquard@uct.ac.za\n",
      "stephen.marquard@uct.ac.za\n",
      "louis@media.berkeley.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801042308.m04N8v6O008125@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "louis@media.berkeley.edu\n",
      "zqian@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801042109.m04L92hb007923@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "zqian@umich.edu\n",
      "rjlowe@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801042044.m04Kiem3007881@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "rjlowe@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "rjlowe@iupui.edu\n",
      "rjlowe@iupui.edu\n",
      "zqian@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801042001.m04K1cO0007738@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "zqian@umich.edu\n",
      "zqian@umich.edu\n",
      "rjlowe@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041948.m04JmdwO007705@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "rjlowe@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "rjlowe@iupui.edu\n",
      "rjlowe@iupui.edu\n",
      "cwen@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041635.m04GZQGZ007313@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "hu2@iupui.edu\n",
      "cwen@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041633.m04GX6eG007292@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "hu2@iupui.edu\n",
      "gsilver@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041611.m04GB1Lb007221@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "gsilver@umich.edu\n",
      "gsilver@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041610.m04GA5KP007209@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "gsilver@umich.edu\n",
      "zqian@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041609.m04G9EuX007197@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "zqian@umich.edu\n",
      "gsilver@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041608.m04G8d7w007184@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "gsilver@umich.edu\n",
      "gsilver@umich.edu\n",
      "wagnermr@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041537.m04Fb6Ci007092@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "wagnermr@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "wagnermr@iupui.edu\n",
      "wagnermr@iupui.edu\n",
      "zqian@umich.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041515.m04FFv42007050@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "source@collab.sakaiproject.org\n",
      "zqian@umich.edu\n",
      "zqian@umich.edu\n",
      "antranig@caret.cam.ac.uk\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041502.m04F21Jo007031@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "antranig@caret.cam.ac.uk\n",
      "source@collab.sakaiproject.org\n",
      "antranig@caret.cam.ac.uk\n",
      "antranig@caret.cam.ac.uk\n",
      "gopal.ramasammycook@gmail.com\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041403.m04E3psW006926@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "gopal.ramasammycook@gmail.com\n",
      "source@collab.sakaiproject.org\n",
      "gopal.ramasammycook@gmail.com\n",
      "gopal.ramasammycook@gmail.com\n",
      "david.horwitz@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041200.m04C0gfK006793@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801041106.m04B6lK3006677@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801040947.m049lUxo006517@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "josrodri@iupui.edu\n",
      "david.horwitz@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801040932.m049W2i5006493@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "david.horwitz@uct.ac.za\n",
      "david.horwitz@uct.ac.za\n",
      "josrodri@iupui.edu\n",
      "stephen.marquard@uct.ac.za\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801040905.m0495rWB006420@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "stephen.marquard@uct.ac.za\n",
      "source@collab.sakaiproject.org\n",
      "stephen.marquard@uct.ac.za\n",
      "stephen.marquard@uct.ac.za\n",
      "louis@media.berkeley.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801040023.m040NpCc005473@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "louis@media.berkeley.edu\n",
      "louis@media.berkeley.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801032216.m03MGhDa005292@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "source@collab.sakaiproject.org\n",
      "louis@media.berkeley.edu\n",
      "louis@media.berkeley.edu\n",
      "ray@media.berkeley.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801032205.m03M5Ea7005273@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "ray@media.berkeley.edu\n",
      "source@collab.sakaiproject.org\n",
      "ray@media.berkeley.edu\n",
      "ray@media.berkeley.edu\n",
      "cwen@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801032133.m03LX3gG005191@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801032127.m03LRUqH005177@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "wagnermr@iupui.edu\n",
      "cwen@iupui.edu\n",
      "postmaster@collab.sakaiproject.org\n",
      "200801032122.m03LMFo4005148@nakamura.uits.iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "source@collab.sakaiproject.org\n",
      "cwen@iupui.edu\n",
      "cwen@iupui.edu\n",
      "wagnermr@iupui.edu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 4 \n",
    "Extract all incoming email addresses as a list from the email_exchange_big.txt file.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_email_addresses(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Use a regular expression to find email addresses\n",
    "    email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "    email_addresses = email_pattern.findall(content)\n",
    "\n",
    "    return email_addresses\n",
    "\n",
    "# Example usage\n",
    "file_path = 'email_exchange.txt'\n",
    "email_list = extract_email_addresses(file_path)\n",
    "\n",
    "# Print the extracted email addresses\n",
    "for email in email_list:\n",
    "    print(email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 20),\n",
       " ('to', 14),\n",
       " ('a', 13),\n",
       " ('of', 9),\n",
       " ('for', 8),\n",
       " ('development', 8),\n",
       " ('is', 6),\n",
       " ('it', 6),\n",
       " ('software', 6),\n",
       " ('the', 5)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Question 5\n",
    "Find the most common words in the English language. Call the name of your function find_most_common_words,\n",
    "it will take two parameters - a string or a file and a positive integer, indicating the number of words. \n",
    "Your function will return an array of tuples in descending order.'''\n",
    "\n",
    "def find_most_common_words(file_path, num_words):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        \n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    most_common = sorted_words[:num_words]\n",
    "\n",
    "    return most_common\n",
    "result = find_most_common_words('sample.txt', 10)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 20), ('to', 14), ('a', 13), ('of', 9), ('for', 8)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_common_words('sample.txt', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words in Obama's speech are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 129),\n",
       " ('and', 113),\n",
       " ('of', 81),\n",
       " ('to', 70),\n",
       " ('our', 67),\n",
       " ('we', 62),\n",
       " ('that', 50),\n",
       " ('a', 48),\n",
       " ('is', 36),\n",
       " ('in', 25)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Question 6\n",
    "\n",
    "Use the function, find_most_frequent_words to find: \n",
    "a) The ten most frequent words used in Obama's speech \n",
    "b) The ten most frequent words used in Michelle's speech \n",
    "c) The ten most frequent words used in Trump's speech \n",
    "d) The ten most frequent words used in Melina's speech'''\n",
    "\n",
    "\n",
    "michelle_obama_speech = './michelle_obama_speech.txt'\n",
    "\n",
    "obama_speech = './obama_speech.txt'\n",
    "\n",
    "trump_speech = 'donald_speech.txt'\n",
    "\n",
    "melina_trump_speech  = 'melina_trump_speech.txt '\n",
    "\n",
    "print(\"The most frequent words in Obama's speech are :\")\n",
    "find_most_common_words(obama_speech, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words in michelle speech are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('and', 96),\n",
       " ('the', 85),\n",
       " ('to', 84),\n",
       " ('that', 50),\n",
       " ('of', 46),\n",
       " ('a', 41),\n",
       " ('he', 37),\n",
       " ('in', 36),\n",
       " ('my', 28),\n",
       " ('i', 28)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The most frequent words in michelle speech are :\")\n",
    "find_most_common_words(michelle_obama_speech, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words in trump_speech speech are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 65),\n",
       " ('and', 59),\n",
       " ('we', 44),\n",
       " ('will', 40),\n",
       " ('of', 38),\n",
       " ('to', 32),\n",
       " ('our', 30),\n",
       " ('is', 20),\n",
       " ('america', 17),\n",
       " ('for', 13)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The most frequent words in trump_speech speech are :\")\n",
    "find_most_common_words(trump_speech, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent words in melina speech are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('and', 77),\n",
       " ('to', 55),\n",
       " ('the', 52),\n",
       " ('is', 29),\n",
       " ('i', 28),\n",
       " ('for', 27),\n",
       " ('of', 25),\n",
       " ('that', 24),\n",
       " ('a', 22),\n",
       " ('you', 21)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The most frequent words in melina speech are :\")\n",
    "find_most_common_words(melina_trump_speech, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 17.80%\n"
     ]
    }
   ],
   "source": [
    "#Question 7\n",
    "\n",
    "'''Write a python application that checks similarity between two texts. \n",
    "It takes a file or a string as a parameter and it will evaluate the similarity of the two texts. \n",
    "For instance check the similarity between the transcripts of Michelle's and Melina's speech. \n",
    "You may need a couple of functions, function to clean the text(clean_text), \n",
    "function to remove support words(remove_support_words) and finally to check the similarity(check_text_similarity). \n",
    "List of stop words are in the data directory'''\n",
    "\n",
    "\n",
    "import re\n",
    "from stop_words import stop_words\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stop_words(text, stop_words):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def calculate_similarity(text1, text2):\n",
    "    # Tokenize the texts\n",
    "    tokens1 = set(text1.split())\n",
    "    tokens2 = set(text2.split())\n",
    "\n",
    "    # Calculate Jaccard similarity coefficient\n",
    "    intersection = len(tokens1.intersection(tokens2))\n",
    "    union = len(tokens1) + len(tokens2) - intersection\n",
    "    similarity = intersection / union if union > 0 else 0\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# Read the transcripts\n",
    "michelle_speech = open(michelle_obama_speech, 'r').read()\n",
    "melina_speech = open(melina_trump_speech, 'r',).read()\n",
    "\n",
    "# Clean and remove stop words\n",
    "cleaned_michelle_speech = remove_stop_words(clean_text(michelle_speech), stop_words)\n",
    "cleaned_melina_speech = remove_stop_words(clean_text(melina_speech), stop_words)\n",
    "\n",
    "# Calculate and print similarity\n",
    "similarity = calculate_similarity(cleaned_michelle_speech, cleaned_melina_speech)\n",
    "print(f\"Similarity: {similarity:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Repeated Words:\n",
      "the: 866 times\n",
      "and: 793 times\n",
      "to: 625 times\n",
      "i: 585 times\n",
      "of: 535 times\n",
      "a: 528 times\n",
      "in: 377 times\n",
      "is: 375 times\n",
      "that: 363 times\n",
      "you: 362 times\n"
     ]
    }
   ],
   "source": [
    "# Question 8\n",
    "\n",
    "# Find the 10 most repeated words in the romeo_and_juliet.txt\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    return cleaned_text\n",
    "\n",
    "def find_most_repeated_words(file_path, top_n=10):\n",
    "    # Read the text from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = cleaned_text.split()\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Find the top N most repeated words\n",
    "    most_repeated_words = word_counts.most_common(top_n)\n",
    "\n",
    "    return most_repeated_words\n",
    "\n",
    "\n",
    "    # Specify the path to the file\n",
    "file_path = \"romeo_juliet.txt\"\n",
    "    # Find and print the 10 most repeated words\n",
    "most_repeated_words = find_most_repeated_words(file_path, top_n=10)\n",
    "print(\"10 Most Repeated Words:\")\n",
    "for word, count in most_repeated_words:\n",
    "     print(f\"{word}: {count} times\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
