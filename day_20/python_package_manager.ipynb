{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a new folder named mypacakge inside 30DaysOfPython folder Create an empty init.py \n",
    "file in the mypackage folder. Create modules arithmetic.py and greet.py with following code:\n",
    "'''\n",
    "#The folder structure of your package should look like this:\n",
    "'''\n",
    "─ mypackage\n",
    "    ├── __init__.py\n",
    "    ├── arithmetic.py\n",
    "    └── greet.py\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mypackage import arithematics\n",
    "arithematics.add_numbers(1, 2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithematics.subtract(5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithematics.multiple(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithematics.division(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithematics.remainder(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arithematics.power(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abubakar Al-amin, welcome to 30DaysOfPython Challenge!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mypackage import greet\n",
    "greet.greet_person('Abubakar', 'Al-amin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises: Day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nRead this url and find the 10 most frequent words. \\nromeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt' \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1\n",
    "\n",
    "'''\n",
    "Read this url and find the 10 most frequent words. \n",
    "romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt' \n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Frequent Words:\n",
      "lia: 23 times\n",
      "li: 14 times\n",
      "meta: 13 times\n",
      "div: 13 times\n",
      "ul: 10 times\n",
      "input: 9 times\n",
      "link: 7 times\n",
      "gutenberg: 5 times\n",
      "project: 4 times\n",
      "relstylesheet: 4 times\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "from stop_words import stop_words\n",
    "import re\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    # Fetch the content from the URL\n",
    "    response = requests.get(url)\n",
    "    text = response.text\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = cleaned_text.split()\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def find_most_frequent_words(tokens, top_n=10):\n",
    "    # Remove common English stop words\n",
    "    \n",
    "\n",
    "    # Filter out stop words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(filtered_tokens)\n",
    "\n",
    "    # Find the top N most frequent words\n",
    "    most_frequent_words = word_counts.most_common(top_n)\n",
    "\n",
    "    return most_frequent_words\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the URL\n",
    "    romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "    # Get text from the URL\n",
    "    text_from_url = get_text_from_url(romeo_and_juliet_url)\n",
    "\n",
    "    # Clean and tokenize the text\n",
    "    tokens = clean_and_tokenize(text_from_url)\n",
    "\n",
    "    # Find and print the 10 most frequent words\n",
    "    most_frequent_words = find_most_frequent_words(tokens, top_n=10)\n",
    "    print(\"10 Most Frequent Words:\")\n",
    "    for word, count in most_frequent_words:\n",
    "        print(f\"{word}: {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weight Statistics (Metric):\n",
      "  Min: 0.907184\n",
      "  Max: 2.26796\n",
      "  Mean: 1.462326447761195\n",
      "  Mode: [1.360776]\n",
      "  Median: 1.360776\n",
      "\n",
      "Lifespan Statistics:\n",
      "  Min: 8.0\n",
      "  Max: 18.0\n",
      "  Mean: 12.074626865671641\n",
      "  Mode: [12.0]\n",
      "  Median: 12.0\n",
      "\n",
      "Frequency Table - Country:\n",
      "Counter({'United States': 28, 'United Kingdom': 8, 'Russia': 4, 'Thailand': 4, 'Egypt': 3, 'Canada': 3, 'France': 2, 'Burma': 2, 'Turkey': 2, 'Greece': 1, 'United Arab Emirates': 1, 'Australia': 1, 'Cyprus': 1, 'China': 1, 'Japan': 1, 'Isle of Man': 1, 'Norway': 1, 'Iran (Persia)': 1, 'Singapore': 1, 'Somalia': 1})\n",
      "\n",
      "Frequency Table - Breed:\n",
      "Counter({'Abyssinian': 1, 'Aegean': 1, 'American Bobtail': 1, 'American Curl': 1, 'American Shorthair': 1, 'American Wirehair': 1, 'Arabian Mau': 1, 'Australian Mist': 1, 'Balinese': 1, 'Bambino': 1, 'Bengal': 1, 'Birman': 1, 'Bombay': 1, 'British Longhair': 1, 'British Shorthair': 1, 'Burmese': 1, 'Burmilla': 1, 'California Spangled': 1, 'Chantilly-Tiffany': 1, 'Chartreux': 1, 'Chausie': 1, 'Cheetoh': 1, 'Colorpoint Shorthair': 1, 'Cornish Rex': 1, 'Cymric': 1, 'Cyprus': 1, 'Devon Rex': 1, 'Donskoy': 1, 'Dragon Li': 1, 'Egyptian Mau': 1, 'European Burmese': 1, 'Exotic Shorthair': 1, 'Havana Brown': 1, 'Himalayan': 1, 'Japanese Bobtail': 1, 'Javanese': 1, 'Khao Manee': 1, 'Korat': 1, 'Kurilian': 1, 'LaPerm': 1, 'Maine Coon': 1, 'Malayan': 1, 'Manx': 1, 'Munchkin': 1, 'Nebelung': 1, 'Norwegian Forest Cat': 1, 'Ocicat': 1, 'Oriental': 1, 'Persian': 1, 'Pixie-bob': 1, 'Ragamuffin': 1, 'Ragdoll': 1, 'Russian Blue': 1, 'Savannah': 1, 'Scottish Fold': 1, 'Selkirk Rex': 1, 'Siamese': 1, 'Siberian': 1, 'Singapura': 1, 'Snowshoe': 1, 'Somali': 1, 'Sphynx': 1, 'Tonkinese': 1, 'Toyger': 1, 'Turkish Angora': 1, 'Turkish Van': 1, 'York Chocolate': 1})\n"
     ]
    }
   ],
   "source": [
    "#Question\n",
    "'''\n",
    "Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "Create a frequency table of country and breed of cats\n",
    "'''\n",
    "\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "def get_cats_data(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    cats_data = response.json()\n",
    "    return cats_data\n",
    "\n",
    "def convert_weight_to_metric(weight):\n",
    "    # Assuming the weight is given in pounds, convert it to kilograms\n",
    "    pounds_to_kilograms = 0.453592\n",
    "    return weight * pounds_to_kilograms\n",
    "\n",
    "def mean(values):\n",
    "    return sum(values) / len(values) if len(values) > 0 else 0\n",
    "\n",
    "def mode(values):\n",
    "    counter = Counter(values)\n",
    "    max_count = max(counter.values())\n",
    "    mode_values = [key for key, count in counter.items() if count == max_count]\n",
    "    return mode_values\n",
    "\n",
    "def median(values):\n",
    "    sorted_values = sorted(values)\n",
    "    n = len(sorted_values)\n",
    "    mid = n // 2\n",
    "    return (sorted_values[mid] + sorted_values[mid - 1]) / 2 if n % 2 == 0 else sorted_values[mid]\n",
    "\n",
    "def process_cat_stats(cats_data):\n",
    "    weights = [cat['weight']['metric'].split()[0] for cat in cats_data if 'weight' in cat]\n",
    "    lifespans = [cat['life_span'].split()[0] for cat in cats_data if 'life_span' in cat]\n",
    "\n",
    "    weights_numeric = [float(weight) for weight in weights]\n",
    "    lifespans_numeric = [float(lifespan) for lifespan in lifespans]\n",
    "\n",
    "    return weights_numeric, lifespans_numeric\n",
    "\n",
    "def print_statistics(title, values):\n",
    "    print(f\"\\n{title}:\")\n",
    "    print(f\"  Min: {min(values)}\")\n",
    "    print(f\"  Max: {max(values)}\")\n",
    "    print(f\"  Mean: {mean(values)}\")\n",
    "    print(f\"  Mode: {mode(values)}\")\n",
    "    print(f\"  Median: {median(values)}\")\n",
    "\n",
    "def create_frequency_table(data, key):\n",
    "    counter = Counter(item[key] for item in data if key in item)\n",
    "    return counter\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "    # Get cats data from the API\n",
    "    cats_data = get_cats_data(cats_api)\n",
    "\n",
    "    # Process weight and lifespan statistics\n",
    "    weights, lifespans = process_cat_stats(cats_data)\n",
    "\n",
    "    # Convert weights to metric units\n",
    "    weights_metric = [convert_weight_to_metric(weight) for weight in weights]\n",
    "\n",
    "    # Print weight statistics\n",
    "    print_statistics(\"Weight Statistics (Metric)\", weights_metric)\n",
    "\n",
    "    # Print lifespan statistics\n",
    "    print_statistics(\"Lifespan Statistics\", lifespans)\n",
    "\n",
    "    # Create frequency table of country and breed\n",
    "    country_frequency = create_frequency_table(cats_data, 'origin')\n",
    "    breed_frequency = create_frequency_table(cats_data, 'name')\n",
    "\n",
    "    print(\"\\nFrequency Table - Country:\")\n",
    "    print(country_frequency)\n",
    "\n",
    "    print(\"\\nFrequency Table - Breed:\")\n",
    "    print(breed_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Largest Countries:\n",
      "Russia - Area: 17098242.0 square kilometers\n",
      "Antarctica - Area: 14000000.0 square kilometers\n",
      "Canada - Area: 9984670.0 square kilometers\n",
      "China - Area: 9706961.0 square kilometers\n",
      "United States - Area: 9372610.0 square kilometers\n",
      "Brazil - Area: 8515767.0 square kilometers\n",
      "Australia - Area: 7692024.0 square kilometers\n",
      "India - Area: 3287590.0 square kilometers\n",
      "Argentina - Area: 2780400.0 square kilometers\n",
      "Kazakhstan - Area: 2724900.0 square kilometers\n",
      "\n",
      "Top 10 Most Spoken Languages:\n",
      "eng - Number of Countries: 91\n",
      "fra - Number of Countries: 46\n",
      "ara - Number of Countries: 25\n",
      "spa - Number of Countries: 24\n",
      "por - Number of Countries: 10\n",
      "nld - Number of Countries: 7\n",
      "rus - Number of Countries: 7\n",
      "deu - Number of Countries: 5\n",
      "zho - Number of Countries: 5\n",
      "swa - Number of Countries: 4\n",
      "\n",
      "Total Number of Languages: 155\n"
     ]
    }
   ],
   "source": [
    "#Question 3\n",
    "''' \n",
    "Read the countries API and find\n",
    "the 10 largest countries\n",
    "the 10 most spoken languages\n",
    "the total number of languages in the countries API\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_countries_data(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    countries_data = response.json()\n",
    "    return countries_data\n",
    "\n",
    "def get_largest_countries(countries_data, num_countries=10):\n",
    "    sorted_countries = sorted(countries_data, key=lambda x: x['area'], reverse=True)\n",
    "    return sorted_countries[:num_countries]\n",
    "\n",
    "def get_most_spoken_languages(countries_data, num_languages=10):\n",
    "    all_languages = [language for country in countries_data for language in country.get(\"languages\", [])]\n",
    "    language_counts = dict.fromkeys(set(all_languages), 0)\n",
    "\n",
    "    for language in all_languages:\n",
    "        language_counts[language] += 1\n",
    "\n",
    "    sorted_languages = sorted(language_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_languages[:num_languages]\n",
    "\n",
    "def get_total_languages(countries_data):\n",
    "    all_languages = [language for country in countries_data for language in country.get(\"languages\", [])]\n",
    "    unique_languages = set(all_languages)\n",
    "    return len(unique_languages)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    countries_api = 'https://restcountries.com/v3.1/all'\n",
    "\n",
    "    # Get countries data from the API\n",
    "    countries_data = get_countries_data(countries_api)\n",
    "\n",
    "    # Get the 10 largest countries\n",
    "    largest_countries = get_largest_countries(countries_data)\n",
    "    print(\"\\nTop 10 Largest Countries:\")\n",
    "    for country in largest_countries:\n",
    "        print(f\"{country['name']['common']} - Area: {country['area']} square kilometers\")\n",
    "\n",
    "    # Get the 10 most spoken languages\n",
    "    most_spoken_languages = get_most_spoken_languages(countries_data)\n",
    "    print(\"\\nTop 10 Most Spoken Languages:\")\n",
    "    for language, count in most_spoken_languages:\n",
    "        print(f\"{language} - Number of Countries: {count}\")\n",
    "\n",
    "    # Get the total number of languages in the countries API\n",
    "    total_languages = get_total_languages(countries_data)\n",
    "    print(f\"\\nTotal Number of Languages: {total_languages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching webpage: 404 Client Error: Not Found for url: https://archive.ics.uci.edu/datasets.php\n"
     ]
    }
   ],
   "source": [
    "#Question 4\n",
    "''' \n",
    "UCI is one of the most common places to get data sets for data science and machine learning. \n",
    "Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php).\n",
    "Without additional libraries it will be difficult, so you may try it with BeautifulSoup4\n",
    "'''\n",
    "\n",
    "import requests\n",
    "\n",
    "def fetch_webpage(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching webpage: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uci_url = \"https://archive.ics.uci.edu/ml/datasets.php\"\n",
    "    \n",
    "    # Fetch the content of the UCI Machine Learning Repository page\n",
    "    webpage_content = fetch_webpage(uci_url)\n",
    "\n",
    "    # Display the content (for testing purposes)\n",
    "    if webpage_content:\n",
    "        print(webpage_content[:500])  # Displaying the first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: UCI Machine Learning Repository\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/datasets.php\"\n",
    "\n",
    "# Send an HTTP request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find and print the title of the page\n",
    "title = soup.title\n",
    "print(f\"Page Title: {title.text.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
